# ML Algorithms from Scratch

This repository implements machine learning algorithms from scratch to provide a deep understanding of the underlying mathematical concepts and optimization techniques.

## Objective

Learn machine learning algorithms by building them from the ground up. Gain:
- **Mathematical Intuition**: Deep understanding of foundations
- **Implementation Skills**: Step-by-step algorithm building
- **Visual Learning**: Interactive plots and visualizations
- **Practical Application**: Real-world usage with sample data

## Why From Scratch?

- **Deep Understanding**: Know every component of the algorithm
- **Mathematical Clarity**: See how math translates to code
- **Customization**: Modify and experiment with approaches
- **Foundation**: Build skills for advanced ML concepts

## Repository Structure

```
mlalgosfromscratch/
├── linearRegression/     # Linear regression implementation
├── logisticRegression/   # Logistic regression implementation
├── decisionTree/         # Decision tree implementation
├── requirements.txt      # Dependencies for all algorithms
└── README.md            # This file
```

## ML Algorithms

- [X] **Linear Regression** - Regression algorithm with gradient descent
- [X] **Logistic Regression** - Classification algorithm with sigmoid function
- [X] **Decision Trees** - Classification and regression trees
- [ ] **K-Means Clustering** - Unsupervised learning
- [ ] **Neural Networks** - Multi-layer perceptron
- [ ] **Support Vector Machines** - Linear and non-linear SVMs
- [ ] **Random Forest** - Ensemble learning
- [ ] **K-Nearest Neighbors** - Instance-based learning
- [ ] **Naive Bayes** - Probabilistic classifier
- [ ] **Principal Component Analysis** - Dimensionality reduction

## Getting Started

```bash
# Install dependencies
pip install -r requirements.txt

# Run implementations
cd linearRegression
python main.py

cd ../logisticRegression
python main.py

cd ../decisionTree
python main.py
```

## Key Concepts Covered

- **Cost Functions**: MSE, Log Loss
- **Gradient Descent**: Optimization techniques
- **Activation Functions**: Linear, Sigmoid
- **Evaluation Metrics**: Accuracy, Precision, Recall, F1-score
- **Visualization**: Training progress, decision boundaries
